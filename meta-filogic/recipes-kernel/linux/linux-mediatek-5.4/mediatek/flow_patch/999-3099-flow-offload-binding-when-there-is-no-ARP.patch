From b512ce1f521f039a73237f70625d11eaa1a725cd Mon Sep 17 00:00:00 2001
From: Bo-Cun Chen <bc-bocun.chen@mediatek.com>
Date: Tue, 4 Jun 2024 23:02:50 +0800
Subject: [PATCH] flow offload binding when there is no ARP

---
 net/netfilter/xt_FLOWOFFLOAD.c | 35 ++++++++++++++++++++++++----------
 1 file changed, 25 insertions(+), 10 deletions(-)

diff --git a/net/netfilter/xt_FLOWOFFLOAD.c b/net/netfilter/xt_FLOWOFFLOAD.c
index 53fca27..50cdda1 100644
--- a/net/netfilter/xt_FLOWOFFLOAD.c
+++ b/net/netfilter/xt_FLOWOFFLOAD.c
@@ -369,7 +369,7 @@ static void nf_dev_path_info(const struct net_device_path_stack *stack,
 			}
 			break;
 		case DEV_PATH_MTK_WDMA:
-			if (is_zero_ether_addr(info->h_source))
+			if (stack->num_paths == 1)
 				memcpy(info->h_source, path->dev->dev_addr, ETH_ALEN);
 			break;
 		default:
@@ -405,28 +405,43 @@ static int nf_dev_fill_forward_path(const struct nf_flow_route *route,
 
 	read_lock_bh(&n->lock);
 	nud_state = n->nud_state;
-	ether_addr_copy(ha, n->ha);
+	if (nud_state & NUD_VALID)
+		ether_addr_copy(ha, n->ha);
 	read_unlock_bh(&n->lock);
 	neigh_release(n);
 
-	if (!(nud_state & NUD_VALID))
-		return -1;
-
 out:
 	return dev_fill_forward_path(dev, ha, stack);
 }
 
-static int nf_dev_forward_path(struct nf_flow_route *route,
+static int nf_dev_forward_path(struct sk_buff *skb,
+				struct nf_flow_route *route,
 				const struct nf_conn *ct,
 				enum ip_conntrack_dir dir,
 				struct net_device **devs)
 {
 	const struct dst_entry *dst = route->tuple[dir].dst;
+	struct ethhdr *eth;
+	enum ip_conntrack_dir skb_dir;
 	struct net_device_path_stack stack;
 	struct nf_forward_info info = {};
 	unsigned char ha[ETH_ALEN];
 	int i;
 
+	if (!(ct->status & IPS_NAT_MASK) && skb_mac_header_was_set(skb) &&
+	    ct->inet6_mode != CT_INET_MODE_IPV6) {
+		eth = eth_hdr(skb);
+		skb_dir = CTINFO2DIR(skb_get_nfct(skb) & NFCT_INFOMASK);
+
+		if (skb_dir != dir) {
+			memcpy(ha, eth->h_source, ETH_ALEN);
+			memcpy(info.h_source, eth->h_dest, ETH_ALEN);
+		} else {
+			memcpy(ha, eth->h_dest, ETH_ALEN);
+			memcpy(info.h_source, eth->h_source, ETH_ALEN);
+		}
+	}
+
 	if (nf_dev_fill_forward_path(route, dst, ct, dir, ha, &stack) >= 0)
 		nf_dev_path_info(&stack, &info, ha);
 
@@ -516,9 +531,9 @@ xt_flowoffload_route_nat(struct sk_buff *skb, const struct nf_conn *ct,
 
 	if (route->tuple[dir].xmit_type	== FLOW_OFFLOAD_XMIT_NEIGH &&
 	    route->tuple[!dir].xmit_type == FLOW_OFFLOAD_XMIT_NEIGH) {
-		if (nf_dev_forward_path(route, ct, dir, devs))
+		if (nf_dev_forward_path(skb, route, ct, dir, devs))
 			return -1;
-		if (nf_dev_forward_path(route, ct, !dir, devs))
+		if (nf_dev_forward_path(skb, route, ct, !dir, devs))
 			return -1;
 	}
 
@@ -547,8 +562,8 @@ xt_flowoffload_route_bridge(struct sk_buff *skb, const struct nf_conn *ct,
 
 	if (route->tuple[dir].xmit_type	== FLOW_OFFLOAD_XMIT_NEIGH &&
 	    route->tuple[!dir].xmit_type == FLOW_OFFLOAD_XMIT_NEIGH) {
-		if (nf_dev_forward_path(route, ct, dir, devs) ||
-		    nf_dev_forward_path(route, ct, !dir, devs)) {
+		if (nf_dev_forward_path(skb, route, ct, dir, devs) ||
+		    nf_dev_forward_path(skb, route, ct, !dir, devs)) {
 			ret = -1;
 			goto err_route_dir2;
 		}
-- 
2.18.0

